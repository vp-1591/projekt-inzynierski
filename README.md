# AntyDezinformator (Antigravity MLOps Edition)

System do wykrywania technik manipulacji w tekstach w jÄ™zyku polskim, oparty na modelu **Bielik-4.5B-Instruct**. Projekt integruje inferencjÄ™, automatyczny trening (SFT) oraz ewaluacjÄ™ w jeden peÅ‚ny cykl MLOps.

## ğŸš€ Architektura Systemu

- **Frontend**: React (Vite) - Nowoczesny interfejs z "Panelem Eksperckim" do zarzÄ…dzania cyklem Å¼ycia modelu.
- **Backend Orchestrator**: FastAPI - Serce systemu zarzÄ…dzajÄ…ce inferencjÄ…, bazÄ… danych (SQLite) i procesami MLOps.
- **Inference**: Ollama - Lokalny serwer LLM obsÅ‚ugujÄ…cy model Bielik z adapterami LoRA.
- **Training (WSL2)**: Unsloth + Hugging Face - Optymalizowany pod kÄ…tem VRAM potok treningowy dziaÅ‚ajÄ…cy w Å›rodowisku Linux (WSL2).

## ğŸ› ï¸ Instalacja i Konfiguracja

### 1. Wymagania SprzÄ™towe (Wersja Deweloperska)
- **GPU**: NVIDIA (min. 8GB VRAM dla treningu 4-bit).
- **OS**: Windows 10/11 z zainstalowanym **WSL2** (Ubuntu).

### 2. Przygotowanie Ollama
1. Zainstaluj [Ollama](https://ollama.ai/).
2. Pobierz bazowy model Bielik (lub zaimportuj z Modelfile):
   ```bash
   ollama create bielik-4.5b -f ./model/Modelfile
   ```

### 3. Konfiguracja Backend (Windows)
1. PrzejdÅº do folderu `backend`.
2. Zainstaluj zaleÅ¼noÅ›ci:
   ```bash
   pip install -r requirements.txt
   ```
3. Uruchom serwer:
   ```bash
   python -m app.main
   ```

### 4. Konfiguracja Training Environment (WSL2)
1. OtwÃ³rz terminal WSL2 (Ubuntu).
2. Zainstaluj wymagane biblioteki:
   ```bash
   pip install unsloth bitsandbytes accelerate torch trl datasets
   ```
3. Upewnij siÄ™, Å¼e masz dostÄ™p do GPU (`nvidia-smi` wewnÄ…trz WSL).

### 5. Konfiguracja Frontend (Windows)
1. PrzejdÅº do folderu `frontend`.
2. Zainstaluj zaleÅ¼noÅ›ci:
   ```bash
   npm install
   ```
3. Uruchom aplikacjÄ™:
   ```bash
   npm run dev
   ```

## ğŸ§  Cykl MLOps (Human-in-the-Loop)

1. **Analiza**: WprowadÅº tekst w gÅ‚Ã³wnym oknie, aby zobaczyÄ‡ wykryte techniki przez aktualny model.
2. **Tryb Ekspercki**: Aktywuj przeÅ‚Ä…cznik w prawym gÃ³rnym rogu.
3. **Trening**: 
   - PrzeÅ›lij plik `.jsonl` z nowymi przykÅ‚adami (format Alpaca/ChatML).
   - System automatycznie uruchomi proces `trainer.py` wewnÄ…trz WSL2.
   - PostÄ™p treningu jest raportowany w czasie rzeczywistym na pasku bocznym.
4. **Ewaluacja**: Po treningu system automatycznie uruchamia benchmark na zbiorze testowym (`model/datasets/mipd_test.jsonl`).
5. **WdroÅ¼enie (Hot-Swap)**: JeÅ›li nowy wynik F1 jest satysfakcjonujÄ…cy, kliknij "PotwierdÅº ZmianÄ™ Modelu". System zaktualizuje Ollama bez restartu usÅ‚ug.

## ğŸ“Š Metryki
System mierzy:
- **PSR (Parsing Success Rate)**: Czy model generuje poprawny JSON?
- **F1 Score**: SkutecznoÅ›Ä‡ klasyfikacji technik manipulacji wzglÄ™dem zbioru zÅ‚otego.

---
*Projekt zrealizowany w ramach pracy inÅ¼ynierskiej.*
